# ğŸ§ª Testes do Backend ProjectFlow

Este diretÃ³rio contÃ©m todos os testes automatizados do backend, organizados em uma estrutura clara e abrangente.

## ğŸ“ Estrutura dos Testes

```
tests/
â”œâ”€â”€ __init__.py                 # ConfiguraÃ§Ã£o do pacote de testes
â”œâ”€â”€ conftest.py                 # Fixtures globais e configuraÃ§Ãµes do pytest
â”œâ”€â”€ README.md                   # Esta documentaÃ§Ã£o
â”œâ”€â”€ fixtures/                   # Factories e fixtures reutilizÃ¡veis
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ factories.py            # Factories com Factory Boy
â”œâ”€â”€ unit/                       # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py          # Testes dos models
â”‚   â”œâ”€â”€ test_services.py        # Testes dos services
â”‚   â”œâ”€â”€ test_schemas.py         # Testes dos schemas
â”‚   â””â”€â”€ test_utils.py           # Testes das utilidades
â””â”€â”€ integration/                # Testes de integraÃ§Ã£o
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_auth_api.py         # Testes das APIs de autenticaÃ§Ã£o
    â”œâ”€â”€ test_project_api.py      # Testes das APIs de projetos
    â”œâ”€â”€ test_user_api.py         # Testes das APIs de usuÃ¡rios
    â””â”€â”€ test_database.py         # Testes de integraÃ§Ã£o com banco
```

## ğŸ·ï¸ Marcadores de Teste

Os testes sÃ£o organizados usando marcadores pytest:

- `@pytest.mark.unit` - Testes unitÃ¡rios (componentes isolados)
- `@pytest.mark.integration` - Testes de integraÃ§Ã£o (interaÃ§Ã£o entre componentes)
- `@pytest.mark.api` - Testes de endpoints da API
- `@pytest.mark.auth` - Testes relacionados Ã  autenticaÃ§Ã£o
- `@pytest.mark.database` - Testes que interagem com banco de dados
- `@pytest.mark.security` - Testes de seguranÃ§a
- `@pytest.mark.slow` - Testes que demoram mais para executar

## ğŸš€ Como Executar os Testes

### PrÃ©-requisitos

```bash
# Instalar dependÃªncias de teste
pip install -r requirements.txt
```

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Todos os testes
python -m pytest

# Ou usando o script personalizado
python run_tests.py
```

### ExecuÃ§Ã£o por Categoria

```bash
# Apenas testes unitÃ¡rios
python run_tests.py --unit

# Apenas testes de integraÃ§Ã£o
python run_tests.py --integration

# Apenas testes de autenticaÃ§Ã£o
python run_tests.py --auth

# Apenas testes de API
python run_tests.py --api

# Apenas testes de seguranÃ§a
python run_tests.py --security
```

### ExecuÃ§Ã£o com RelatÃ³rios

```bash
# Com cobertura de cÃ³digo
python run_tests.py --coverage

# Com relatÃ³rio HTML de cobertura
python run_tests.py --html-report

# Com relatÃ³rio XML (para CI/CD)
python run_tests.py --xml-report

# Modo verboso
python run_tests.py --verbose
```

### ExecuÃ§Ã£o RÃ¡pida

```bash
# Pula testes lentos
python run_tests.py --fast

# ExecuÃ§Ã£o em paralelo (requer pytest-xdist)
python run_tests.py --parallel
```

### Filtros EspecÃ­ficos

```bash
# Testes que correspondem a um padrÃ£o
python run_tests.py --pattern "test_login"

# Apenas um arquivo especÃ­fico
python run_tests.py --file tests/unit/test_models.py

# Combinando filtros
python run_tests.py --unit --pattern "Usuario" --verbose
```

### CenÃ¡rios PrÃ©-definidos

```bash
# Testes de smoke (bÃ¡sicos, rÃ¡pidos)
python run_tests.py smoke

# Testes de regressÃ£o (completos)
python run_tests.py regression

# Testes de seguranÃ§a
python run_tests.py security

# Testes de performance
python run_tests.py performance
```

## ğŸ­ Factories e Fixtures

### Usando Factories

```python
from tests.fixtures.factories import UsuarioFactory, ProjetoFactory

# Criar um usuÃ¡rio de teste
usuario = UsuarioFactory()

# Criar com atributos especÃ­ficos
admin = UsuarioFactory(role='Admin', email='admin@teste.com')

# Criar mÃºltiplos objetos
usuarios = UsuarioFactory.create_batch(5)

# Criar sem salvar no banco (para testes unitÃ¡rios)
usuario_mock = UsuarioFactory.build()
```

### Usando Fixtures

```python
def test_exemplo(sample_user, sample_projeto, db_session):
    """Teste usando fixtures prÃ©-definidas."""
    assert sample_user.id_usuario is not None
    assert sample_projeto.id_responsavel == sample_user.id_usuario
```

### Fixtures DisponÃ­veis

- `app` - InstÃ¢ncia da aplicaÃ§Ã£o Flask
- `client` - Cliente de teste Flask
- `db_session` - SessÃ£o do banco de dados
- `clean_db` - Banco de dados limpo
- `sample_user` - UsuÃ¡rio de exemplo
- `admin_user` - UsuÃ¡rio administrador
- `sample_area` - Ãrea de exemplo
- `sample_projeto` - Projeto de exemplo
- `auth_headers` - Headers de autenticaÃ§Ã£o
- `admin_auth_headers` - Headers de autenticaÃ§Ã£o de admin
- `mock_file_upload` - Mock de upload de arquivo

## âœï¸ Escrevendo Novos Testes

### Testes UnitÃ¡rios

```python
import pytest
from models import Usuario

@pytest.mark.unit
def test_usuario_creation():
    """Testa criaÃ§Ã£o de usuÃ¡rio."""
    usuario = Usuario(
        nome_completo="JoÃ£o Silva",
        email="joao@teste.com",
        cargo="Dev"
    )
    
    assert usuario.nome_completo == "JoÃ£o Silva"
    assert usuario.email == "joao@teste.com"
```

### Testes de IntegraÃ§Ã£o

```python
import pytest
import json

@pytest.mark.integration
@pytest.mark.api
def test_create_user_api(client, clean_db):
    """Testa criaÃ§Ã£o de usuÃ¡rio via API."""
    user_data = {
        'nome_completo': 'Maria Santos',
        'email': 'maria@teste.com',
        'senha': 'senha123'
    }
    
    response = client.post(
        '/api/auth/register',
        data=json.dumps(user_data),
        content_type='application/json'
    )
    
    assert response.status_code == 201
    assert response.get_json()['email'] == 'maria@teste.com'
```

### Testes com AutenticaÃ§Ã£o

```python
@pytest.mark.integration
@pytest.mark.auth
def test_protected_endpoint(client, auth_headers):
    """Testa endpoint protegido."""
    response = client.get('/api/projetos', headers=auth_headers)
    assert response.status_code == 200
```

### Testes de Banco de Dados

```python
@pytest.mark.unit
@pytest.mark.database
def test_user_relationship(db_session, sample_user, sample_projeto):
    """Testa relacionamento entre usuÃ¡rio e projeto."""
    assert sample_projeto.responsavel == sample_user
    assert sample_user.id_usuario == sample_projeto.id_responsavel
```

## ğŸ“Š RelatÃ³rios de Cobertura

### Visualizar Cobertura

```bash
# Gerar relatÃ³rio HTML
python run_tests.py --html-report

# Abrir no navegador
open htmlcov/index.html  # macOS/Linux
start htmlcov/index.html # Windows
```

### Metas de Cobertura

- **MÃ­nimo aceitÃ¡vel**: 70%
- **Meta ideal**: 85%
- **CrÃ­tico**: 95% (para mÃ³dulos de seguranÃ§a)

### Arquivos ExcluÃ­dos da Cobertura

- Arquivos de teste (`test_*.py`)
- MigraÃ§Ãµes de banco
- Arquivos de configuraÃ§Ã£o
- Scripts de deploy

## ğŸ”§ ConfiguraÃ§Ã£o do Ambiente de Teste

### VariÃ¡veis de Ambiente

```bash
# ConfiguraÃ§Ã£o automÃ¡tica pelo conftest.py
FLASK_ENV=testing
DATABASE_URL=sqlite:///:memory:
JWT_SECRET_KEY=test-secret-key
```

### Banco de Dados de Teste

- Usa SQLite em memÃ³ria por padrÃ£o
- Cada teste roda em transaÃ§Ã£o isolada
- Dados sÃ£o limpos automaticamente

### ConfiguraÃ§Ãµes Personalizadas

```python
# Em conftest.py, vocÃª pode personalizar:
@pytest.fixture(scope='session')
def app():
    test_config = {
        'TESTING': True,
        'DATABASE_URL': 'sqlite:///:memory:',
        # Suas configuraÃ§Ãµes personalizadas
    }
    return create_app(test_config)
```

## ğŸš¨ Boas PrÃ¡ticas

### Nomenclatura

- Arquivos: `test_*.py`
- Classes: `TestNomeDoComponente`
- MÃ©todos: `test_descricao_do_que_testa`

### Estrutura de Teste

```python
def test_nome_descritivo(fixtures_necessarias):
    """
    Docstring explicando o que o teste faz.
    
    Given: Estado inicial
    When: AÃ§Ã£o executada
    Then: Resultado esperado
    """
    # Arrange (preparaÃ§Ã£o)
    dados = {'campo': 'valor'}
    
    # Act (aÃ§Ã£o)
    resultado = funcao_testada(dados)
    
    # Assert (verificaÃ§Ã£o)
    assert resultado.status == 'esperado'
    assert 'campo_esperado' in resultado.data
```

### Isolamento

- Cada teste deve ser independente
- Use fixtures para setup/teardown
- NÃ£o dependa da ordem de execuÃ§Ã£o

### Dados de Teste

- Use factories para dados realistas
- NÃ£o use dados hardcoded em produÃ§Ã£o
- Crie cenÃ¡rios edge case

### Performance

- Testes unitÃ¡rios devem ser rÃ¡pidos (< 100ms)
- Use `@pytest.mark.slow` para testes demorados
- Mock dependÃªncias externas

## ğŸ”„ IntegraÃ§Ã£o ContÃ­nua

### GitHub Actions

```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: python run_tests.py --xml-report
      - name: Upload coverage
        uses: codecov/codecov-action@v1
```

### Hooks de Pre-commit

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: tests
        name: Run tests
        entry: python run_tests.py --fast
        language: system
        pass_filenames: false
```

## ğŸ› Debugging de Testes

### Executar Teste EspecÃ­fico

```bash
# Um teste especÃ­fico
python -m pytest tests/unit/test_models.py::TestUsuarioModel::test_criar_usuario_basico -v

# Com debugger
python -m pytest tests/unit/test_models.py::test_funcao --pdb
```

### Logs Durante Testes

```python
import logging

def test_com_logs(caplog):
    """Teste que captura logs."""
    with caplog.at_level(logging.INFO):
        funcao_que_loga()
    
    assert "Mensagem esperada" in caplog.text
```

### Fixtures de Debug

```python
@pytest.fixture
def debug_db(db_session):
    """Fixture que nÃ£o limpa o banco para debug."""
    yield db_session
    # NÃ£o faz rollback para inspecionar dados
```

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o

- [Pytest Documentation](https://docs.pytest.org/)
- [Factory Boy Documentation](https://factoryboy.readthedocs.io/)
- [Flask Testing](https://flask.palletsprojects.com/en/2.0.x/testing/)

### Plugins Ãšteis

- `pytest-cov` - Cobertura de cÃ³digo
- `pytest-mock` - Mocking avanÃ§ado
- `pytest-xdist` - ExecuÃ§Ã£o paralela
- `pytest-flask` - Helpers para Flask

### Comandos Ãšteis

```bash
# Listar todos os testes
python -m pytest --collect-only

# Executar testes que falharam na Ãºltima execuÃ§Ã£o
python -m pytest --lf

# Executar apenas novos testes
python -m pytest --nf

# Mostrar os 10 testes mais lentos
python -m pytest --durations=10
```

---

## ğŸ¤ Contribuindo

1. Escreva testes para toda nova funcionalidade
2. Mantenha cobertura acima de 70%
3. Use factories para dados de teste
4. Documente casos edge
5. Execute todos os testes antes do commit

```bash
# Antes de fazer commit
python run_tests.py --coverage
```

Para dÃºvidas ou sugestÃµes, abra uma issue ou discuta com a equipe! ğŸš€
